{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " string = 'aabbcdd123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.count('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-10-3c4a59d5af61>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-3c4a59d5af61>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    return string[string.index(i)]\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "for i in string: \n",
    "    if string.count(i) == 1: \n",
    "        return string[string.index(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def first_unique(string):\n",
    "    ### create list to append string\n",
    "    unique_char = list()\n",
    "    for letter in string: \n",
    "        ### count letter in string \n",
    "        if string.count(letter) == 1: \n",
    "            ### if it equals one append to list and choose the first\n",
    "            unique_char.append(letter)\n",
    "            return unique_char[0]\n",
    "    ### else do none\n",
    "    return \"None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_unique('112233')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Practice (Data-Analyst)\n",
    "\n",
    "\n",
    "\n",
    "## Question One - Describe a data project you worked on recently. \n",
    "\n",
    "** Answer 1 ** \n",
    "\n",
    "Recently, I had the option of choosing a data of my choice and was ask to make an effective data visulization. The data I chose to explore consisted information of twenty-eight episodes of the Simpsons. I felt this data would create a fun unique effective visualization with Dimple.js because most people would consider themselves a fan of the beloved Simpsons television show. My first instinct when acquring the data was to explore the features that could possible represent an overall analytical landscape. The way I sketched out my data was to explore the content in detail through the Pandas module using Seaborn, Matplotlib and Numpy. The idea I had was how to best represent the possible features that are given in the dataset. First, I looked at the type features wheather they be boolean, time data, integer, strings or float objects. Secondly, I choose the features that would best represent a visualized intepretation of the data like a boxplot, lineplot, bubbleplot and pairplot. Lastly, I tried to wrap the data objects together by having them be represented by a hue, this lead me to a conclusion of the possible features and what sort of best visualization I may proceed with in my project. The featuers I chose in the project were: Viewers in united states by millions, date, imdb rating, title and season of the show. I knew I wanted to capture each feature withitn my visualized data so I decided that a bubble plot would be the best representation of the data with viewers in united states by millions in the y variable and date in the x variable. The reason why I chose a bubble plot is I wanted to create a toolbox feature that contained the title, rating and air date. It gives the reader something to connect with when the hoover over the bubble and se that possibly there favorite episode wasn't or was liked by a majority of the viewership population, while the color hue would represent all twent-eight different seasons of the show. I did not want to overcrowd the chart with legends because in my opinion it was another object I felt unecessary for the reader to analyze. All the information that was needed was contained in each bubble. Personally, this was an exciting project for me because it was unique and a fun dataset to play around with and I believe projects like this is what brings people wanting more visualized data. \n",
    "\n",
    "\n",
    "\n",
    "## Question Two - You are given a ten piece box of chocolate truffles. You know based on the label that six of the pieces have an orange cream filling and four of the pieces have a coconut filling. If you were to eat four pieces in a row, what is the probability that the first two pieces you eat have an orange cream filling and the last two have a coconut filling? Follow-up question: If you were given an identical box of chocolates and again eat four pieces in a row, what is the probability that exactly two contain coconut filling?\n",
    "\n",
    "\n",
    "** Answer 2 Part One ** \n",
    "\n",
    "The way I would approach this problem would be like selecting slots for the amount of orange fillings to coconut fillings. \n",
    "\n",
    "Orange Filling = O \n",
    "Coconut Filling = C \n",
    "\n",
    "slot one O: since I have to fill slot one I have 6 pieces of O from my ten choices the P(O) = 6/10 \n",
    "\n",
    "slot two O since now I have to fill the second slot with O I have only 5 pices to choose from then P(O) = 5/9\n",
    "\n",
    "slot three C: now I have to fill the third slot with C and I have 4 pieces to choose from then P(C) = 4/8\n",
    "\n",
    "slot four C: now I have to fill the forth slot with C and I have 3 pieces left to choose from then P(C) = 3/7 \n",
    "\n",
    "since we have related choices in choosing, the probablity that the first two pieces you eat have an orange cream filling is the product of probabilites ```6/10 * 5/9 * 4/8 * 3/78 = 0.07```\n",
    "\n",
    "\n",
    "\n",
    "** Answer 2 Part Two **\n",
    "\n",
    "First lets write down all the possible combinations: \n",
    "\n",
    "```\n",
    "Comb1  = (O,O,C,C)\n",
    "Comb2  = (O,C,C,O) \n",
    "Comb3  = (C,C,O,O)\n",
    "Comb4  = (C,O,O,C)\n",
    "Comb5  = (O,C,O,C)\n",
    "Comb6  = (C,O,C,O)\n",
    "\n",
    "```\n",
    "\n",
    "There are six different combintions or 4 choose 2. To obtain the total combinations in the entire set we just add the combinations of different O to C which is 16 different, which is the sum of n choose k possibilites: \n",
    "\n",
    "``` n choose k = 1 + 4 + 6 + 4 + 1 = 16. Then we have the P(6/16) = 0.375  or  0.4 ``` \n",
    "\n",
    "So the probablity that you eat exactly two coconut choclate is 6/16 = 0.4. \n",
    "\n",
    "\n",
    "## Question Three - Given the table users:\n",
    "\n",
    "```\n",
    "     Table \"users\"\n",
    "+-------------+-----------+\n",
    "| Column      | Type      |\n",
    "+-------------+-----------+\n",
    "| id          | integer   |\n",
    "| username    | character |\n",
    "| email       | character |\n",
    "| city        | character |\n",
    "| state       | character |\n",
    "| zip         | integer   |\n",
    "| active      | boolean   |\n",
    "+-------------+-----------+\n",
    "\n",
    "```\n",
    "\n",
    "construct a query to find the top 5 states with the highest number of active users. Include the number for each state in the query result. Example result:\n",
    "\n",
    "```\n",
    "+------------+------------------+\n",
    "| state      | num_active_users |\n",
    "+------------+------------------+\n",
    "| New Mexico | 502              |\n",
    "| Alabama    | 495              |\n",
    "| California | 300              |\n",
    "| Maine      | 201              |\n",
    "| Texas      | 189              |\n",
    "+------------+------------------+\n",
    "\n",
    "```\n",
    "\n",
    "** Answer 3 ** \n",
    "\n",
    "``` sql \n",
    "\n",
    "SELECT state, count(id) as sum_active_users from users \n",
    "WHERE active = 1 \n",
    "GROUP BY state \n",
    "ORDER BY sum_active_users DESC \n",
    "limit 5\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Question 4 - Define a function first_unique that takes a string as input and returns the first non-repeated (unique) character in the input string. If there are no unique characters return None. Note: Your code should be in Python.\n",
    "\n",
    "** Answer 4 ** \n",
    "``` python \n",
    "\n",
    "\n",
    "def first_unique(string):\n",
    "    ### create list to append string\n",
    "    unique_char = list()\n",
    "    for letter in string: \n",
    "        ### count letter in string \n",
    "        if string.count(letter) == 1: \n",
    "            ### if it equals one append to list and choose the first\n",
    "            unique_char.append(letter)\n",
    "            return unique_char[0]\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "```\n",
    "Probably a better way to look at this problem but if this was an in-interview test I would go with the slowest way. I know the count is very costly here but since this is a practice interview i'm goign with my gut and the first thing that pops in my head. \n",
    "\n",
    "\n",
    "## Question 5 - What are underfitting and overfitting in the context of Machine Learning? How might you balance them?\n",
    "\n",
    "** Answer 5 - Underfitting ** \n",
    "\n",
    "Underfitting is an occurance when you have selected an algorithm which doesn't capture the overall trend in the data set that well based on the features you have chosen.\n",
    "\n",
    "Possible causes of underfitting: \n",
    "\n",
    "* not enough features \n",
    "* parametizaiton is bad \n",
    "\n",
    "** Answer 5 - Overfitting ** \n",
    "\n",
    "Overfitting is when you have choosen an selected algorithm with very good training set results but the resulst lack on a new data set. You would want to have more Cross-Validation methords to improve this. \n",
    "\n",
    "Possible causes of overfitting:\n",
    "\n",
    "* too many features \n",
    "* Noise \n",
    "* not enought data \n",
    "\n",
    "\n",
    "## Question 6 - f you were to start your data analyst position today, what would be your goals a year from now?\n",
    "\n",
    "\n",
    "** Answer 6 - Job Discription ** \n",
    "\n",
    "``` \n",
    "Radiance Technologies is an employee-owned company with benefits that are unmatched by most companies in the Dayton, OH area. Selected as one of Dayton's Best Places to work in 2017. Radiance offers highly competitive salaries, a relaxed work environment, flexible work schedules and a great benefits package that includes health/dental/life/ vision insurance benefits, employee ownership, generous 401K and profit sharing, and educational reimbursement. Radiance Technologies is a great place to work and succeed in Dayton, Ohio.\n",
    "Radiance is seeking a Machine Learning Engineer who will advance the artificial intelligence capabilities of the National Air and Space Intelligence Center at Wright Patterson Air Force Base. This engineer will provide expertise in data analytics and algorithm development supporting the integration and analysis of diverse data sources and develop machine learning, data mining and statistical algorithms for pattern recognition and anomaly detection. Additionally, this position will improve upon current methods for the automated processing and exploitation of large data sets. This will include R&D on projects involving the exploitation of data from sensors including investigation of state-of-the-art machine learning classification methods to classify and characterize extracted targets of interest.\n",
    "\n",
    "\n",
    "Desired Skills\n",
    "Machine Learning, Natural Language Processing, Computer Vision or equivalent experience\n",
    "R&D on remotely sensed data to include modeling and development of algorithms. Ability to work independently or in a team environment\n",
    "Strong technical writing and oral communication skills\n",
    "Active Secret or Top Secret/SCI clearance\n",
    "Advanced degree (MS/PhD) in data science, mathematics, statistics, computer science, a physical science or engineering is strongly desired\n",
    "A mathematical background (Probability and Statistics)\n",
    "An experienced grasp of version control using Git for nonlinear workflows\n",
    "Thorough understanding of working in research, development and production environments\n",
    "Background in image science, imagery exploitation, spatial analysis, and computer vision are a plus\n",
    "\n",
    "\n",
    "Required Skills\n",
    "Bachelor’s Degree in a quantitative field such as Computer Science, Engineering, Physics, Statistics, or a related field\n",
    "Strong programming skills in at least one of the following languages Python, Matlab, C++\n",
    "US Citizenship with the ability to obtain a clearance\n",
    "Required Experience\n",
    "1 year of experience in Machine Learning\n",
    "A working knowledge of Artificial Neural Networks (ANNs) and Deep Neural Networks (DNNs)\n",
    "Experience in applying core Machine Learning methodologies: Regression, Naive Bayesian classifier, Clustering, Matrix Factorization, k-Nearest Neighbors, Natural Language processing, Decision trees, Support Vector Machines, Neural Networks &\n",
    " Employment Listings\n",
    "Search Current Openings Update Your Profile Create a Job Agent Update Job Agent Recruiting Agency Login\n",
    "                Deep Learning\n",
    "\n",
    "```\n",
    "\n",
    "A year from now I would like to be learning new techniques in Deep Learning Neural Networks such as TensorFlow and be able to work with the team to create new mathematical theories that would benefit the team. I would also like to be a more efficient coder and to be wiser the ways we appraoch ML, ANN and DNNs. While there is never a concreate way to solve a problem it is the training I will be learning with the tearm that will make me a better Analyst. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
