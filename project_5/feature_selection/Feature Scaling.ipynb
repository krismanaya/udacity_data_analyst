{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling \n",
    "\n",
    "** Feature Scaling Formula ** \n",
    "\n",
    "$ x' = \\frac{x - x_{min}}{x_{max} - x_{min}} $\n",
    "\n",
    "* $x$ is the old value before rescaling. \n",
    "* $x_{max} =$ maximum value of old feature before re scaling. \n",
    "* $x_{min} =$ similar, but minimum. \n",
    "\n",
    "### example: \n",
    "\n",
    "Let, $ol = [115,140,175]$. Then, $x_{min}=115$ and $x_{max} = 175$. Therfore, \n",
    "we may use our feature scaling $x_{140}' = \\frac{140 - 115}{175 - 115} = 0.42$. \n",
    "\n",
    "What we may notice here is that our transform features will always be in between $0 \\leq x' \\leq 1$. \n",
    "\n",
    "\n",
    "### Which Algorithm would be affected by feature rescaling \n",
    "\n",
    "* Decision Trees (NO) \n",
    "* SVM with RBF kernel (YES) \n",
    "* Linear Regression (NO) \n",
    "* k-means clustering (YES) \n",
    "\n",
    "* **SVM**  - look at the seperation line seperating the distance. This trade off one dimension \n",
    "* **k-means** - you computer the clustering from all the data points.\n",
    "\n",
    "* **DT** - will give you cuts between the vert and horz.\n",
    "* **LR** - linear regression will have a coeficcient always go togethere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureScaling(arr): \n",
    "    try: \n",
    "        x_prime = []\n",
    "        for x in data: \n",
    "            x_min = min(data)\n",
    "            x_max = max(data)\n",
    "            feature_scaling = (x-x_min)/float(x_max - x_min)\n",
    "            x_prime.append(feature_scaling)\n",
    "            print feature_scaling\n",
    "    except ZeroDivisionError: \n",
    "        return \"Max and Min are the same, you don't need to rescale\", arr[0]\n",
    "    else: \n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featureScaling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "#minmax scalar in sklearn \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([[200000.0],[1000000]]) # weights like before. \n",
    "scaler = MinMaxScaler() #scalar\n",
    "rescaled_weight = scaler.fit_transform(weights) # feature scaling \n",
    "print rescaled_weight # prints the feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How this all works\n",
    "\n",
    "Once you understand the answer, most of the rest of syntax used in the project will become much clearer (So bear with me for a while as I take a few steps back and then answer your question).\n",
    "\n",
    "1. Create an Instance\n",
    "\n",
    "All of the data processors and classifiers that you will be using in this course begin life as a set of instructions called a class (they are 'blueprints' for what the processor or classifier can do).\n",
    "\n",
    "You create an instance from those set of instructions, in the case of scaling that is done in the statement:\n",
    "\n",
    "# create a specific instance of the class `'MinMaxScaler'`\n",
    "``scaler = MinMaxScaler()``\n",
    "where 'scaler' is any name that you choose.\n",
    "\n",
    "'scaler' is now a data object that has attributes (i.e. variables) and methods (i.e. functions) inside it. Where attributes and methods are accessed using 'dot' notation:\n",
    "\n",
    "``scaler.fit()``\n",
    "for example, accesses the function/method '.fit()'\n",
    "\n",
    "2. Accessing attributes and calling methods of that Instance:\n",
    "\n",
    "I will change the code outlined in previous posts a little to make things clearer (and explain the changes that I made later):\n",
    "\n",
    "# call the '.fit()' method on data\n",
    "scaler.fit(finance_features)\n",
    "All data processors and classifier/regressors have a '.fit()' method. Obviously, that '.fit()' method will perform different calculations depending on the purpose of the process (you would expect an instance of 'MinMaxScaler' to calculate the minimum and maximum for each variable passed to '.fit()', whereas you would expect an instance of 'PCA' to calculate the principal components for each variable passed to '.fit()' - the same method name, different calculations).\n",
    "\n",
    "Data processors have a '.transform()' method (which will create the scaled variables for 'MinMaxScaler' and the principal components for 'PCA').\n",
    "\n",
    "(Classifiers don't have a '.transform()' method, they have a '.predict()' method).\n",
    "\n",
    "Why is all of that relevant?\n",
    "\n",
    "Once you call either:\n",
    "\n",
    "# call the '.fit()' method on data\n",
    "``scaler.fit(finance_features)``\n",
    "or\n",
    "\n",
    "# call the '.fit()' method on data and transform the data\n",
    "``rescaled_finance_features = scaler.fit_transform(finance_features)``\n",
    "The instance 'scaler' stores the results of '.fit()' as attributes (which you can access - see the documentation1 - using 'scaler.min_' to see the minimum values, for example).\n",
    "\n",
    "So, that 'instance' is now primed and ready to use those values on any data that you want to transform. That is, the statements:\n",
    "\n",
    "``financial_features_test = numpy.array([200000., 1000000.])\n",
    "financial_features_test_transformed = scaler.transform(financial_features_test)``\n",
    "are creating data (has to have the same number of columns as the data fitted), and then transforming (i.e. scaling) that data, by calling the '.transform()' method .... using the min and the max of the data passed to '.fit()'.\n",
    "\n",
    "3 Wrap-up\n",
    "\n",
    "You can use data processors to fit and transform in the same step (using '.fit_transform()') but, in trying to understand how the process that you are asking about works, it is easier to split the steps into '.fit()' and '.transform()'.\n",
    "\n",
    "'.fit()' performs the calculations that allow you to '.transform()' (you can see this if you try to call '.transform()' before you call '.fit()' as an error will be thrown). Those calculations reside in the instance (until you '.fit()' again, when those values/attributes will be over-written).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
