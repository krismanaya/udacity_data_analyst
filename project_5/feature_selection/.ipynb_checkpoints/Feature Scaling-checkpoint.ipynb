{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling \n",
    "\n",
    "** Feature Scaling Formula ** \n",
    "\n",
    "$ x' = \\frac{x - x_{min}}{x_{max} - x_{min}} $\n",
    "\n",
    "* $x$ is the old value before rescaling. \n",
    "* $x_{max} =$ maximum value of old feature before re scaling. \n",
    "* $x_{min} =$ similar, but minimum. \n",
    "\n",
    "### example: \n",
    "\n",
    "Let, $ol = [115,140,175]$. Then, $x_{min}=115$ and $x_{max} = 175$. Therfore, \n",
    "we may use our feature scaling $x_{140}' = \\frac{140 - 115}{175 - 115} = 0.42$. \n",
    "\n",
    "What we may notice here is that our transform features will always be in between $0 \\leq x' \\leq 1$. \n",
    "\n",
    "\n",
    "### Which Algorithm would be affected by feature rescaling \n",
    "\n",
    "* Decision Trees (NO) \n",
    "* SVM with RBF kernel (YES) \n",
    "* Linear Regression (NO) \n",
    "* k-means clustering (YES) \n",
    "\n",
    "* **SVM**  - look at the seperation line seperating the distance. This trade off one dimension \n",
    "* **k-means** - you computer the clustering from all the data points.\n",
    "\n",
    "* **DT** - will give you cuts between the vert and horz.\n",
    "* **LR** - linear regression will have a coeficcient always go togethere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureScaling(arr): \n",
    "    try: \n",
    "        x_prime = []\n",
    "        for x in data: \n",
    "            x_min = min(data)\n",
    "            x_max = max(data)\n",
    "            feature_scaling = (x-x_min)/float(x_max - x_min)\n",
    "            x_prime.append(feature_scaling)\n",
    "            print feature_scaling\n",
    "    except ZeroDivisionError: \n",
    "        return \"Max and Min are the same, you don't need to rescale\", arr[0]\n",
    "    else: \n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featureScaling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.41666667]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#minmax scalar in sklearn \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([[200000.0],[1000000]]) # weights like before. \n",
    "scaler = MinMaxScaler() #scalar\n",
    "rescaled_weight = scaler.fit_transform(weights) # feature scaling \n",
    "print rescaled_weight # prints the feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
